{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the Keras Sequential model\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Specifying the input shape\n",
    "\n",
    "Sequential model에서는 첫번째 layer에만  input shape에 대한 정보를 전달(초기화)해주면 됨.\n",
    "\n",
    "(나머자는 따라서 정해지니까-)\n",
    "\n",
    "1D layers : input_shape (batch dimension is not included)\n",
    "\n",
    "2D layers : input_dim (ex: Dense) \n",
    "\n",
    "3D layers : input_dim and input_length\n",
    "\n",
    "'fixed' batch size for inputs가 필요하다면, batch_size를 전달해야함.\n",
    "\n",
    "(stateful recurrent networks에 유용하게 쓰임)\n",
    "\n",
    "ex) batch_szie=32, input_shape=(6,8) => input들의 모든 batch는 (32, 6, 8)의 batch shape을 가지게 됨\n",
    "\n",
    "ex) 아래의 두 코드는 동일함!\n",
    "```python\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "model.add(Dense(32, input_dim=784))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Compilation\n",
    "\n",
    "optimizer: rmsprop, adagrad, ...\n",
    "\n",
    "loss function: categorical_crossentropy, mse, ...\n",
    "\n",
    "metrics: accuracy, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a multi-class classification problem\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "- For a mean squared error regression problem\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='mse')\n",
    "```\n",
    "\n",
    "- For custom metrics\n",
    "\n",
    "```python\n",
    "import keras.backend as K\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy', mean_pred])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Training\n",
    "\n",
    "numpy arrays of input data and labels\n",
    "\n",
    "'fit' functiopn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 219us/step - loss: 0.7122 - acc: 0.4910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.7013 - acc: 0.4970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6958 - acc: 0.5120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6910 - acc: 0.5300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6876 - acc: 0.5340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6841 - acc: 0.5370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6786 - acc: 0.5720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6798 - acc: 0.5650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6768 - acc: 0.5610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6689 - acc: 0.5980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f047e690828>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 smaples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Example: MLP for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 735us/step - loss: 0.7242 - acc: 0.4880\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.7110 - acc: 0.5020\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6949 - acc: 0.5240\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.7011 - acc: 0.5100\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.7069 - acc: 0.4890\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 0.6905 - acc: 0.5360\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 0.6987 - acc: 0.4990\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 12us/step - loss: 0.6954 - acc: 0.5220\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 0.6937 - acc: 0.4990\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 0.6931 - acc: 0.5310\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 13us/step - loss: 0.6942 - acc: 0.5130\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 13us/step - loss: 0.6932 - acc: 0.5330\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 0.6907 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 0.6863 - acc: 0.5500\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6942 - acc: 0.5130\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6899 - acc: 0.5410\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6905 - acc: 0.5440\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6906 - acc: 0.5270\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6894 - acc: 0.5270\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 0.6883 - acc: 0.5340\n",
      "100/100 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Try to change input information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
